{"cells":[{"cell_type":"markdown","metadata":{"id":"nU6AVuvzqDu1"},"source":["## **链接到谷歌云盘**"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"9Yh-WIMsrNl6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699944091118,"user_tz":-480,"elapsed":72550,"user":{"displayName":"田雪","userId":"12940516194408436158"}},"outputId":"9c2c73eb-d567-4fe2-c351-1982cbfbc2d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"Gq4QA-Tlr_NJ"},"source":["## **1.安装依赖**\n","完成微调，需要安装openai和环境变量"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16476,"status":"ok","timestamp":1699944165246,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"Nf_ibxWDr7zC","outputId":"186342b9-082c-4a60-c8c5-10ccfaacf3ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.2.4-py3-none-any.whl (220 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.2/220.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n","Collecting httpcore (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 openai-1.2.4\n","Collecting load_dotenv\n","  Downloading load_dotenv-0.1.0-py3-none-any.whl (7.2 kB)\n","Collecting python-dotenv (from load_dotenv)\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Installing collected packages: python-dotenv, load_dotenv\n","Successfully installed load_dotenv-0.1.0 python-dotenv-1.0.0\n"]}],"source":["!pip install --upgrade openai\n","!pip install load_dotenv"]},{"cell_type":"markdown","metadata":{"id":"-IIXlk0PtFs0"},"source":["## **2.引入openai环境**\n","\n","注意此处需要填写您自己的api_key"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":907,"status":"ok","timestamp":1699944199057,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"llaD5Wv-qDu4"},"outputs":[],"source":["import openai\n","import os\n","from dotenv import load_dotenv, find_dotenv\n","_ = load_dotenv('/content/drive/MyDrive/Colab/.env')\n","\n","openai.api_key  = os.environ['OPENAI_API_KEY']"]},{"cell_type":"markdown","metadata":{"id":"DZ6BLzvFqDu5"},"source":["## **3.数据处理**\n","将数据格式处理成标准化的JSON-L格式，即Chat completions API中所要求的messages数组形式，每行一个如下所示的JSON对象。\n","``` JSON\n","{\"messages\": [{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": \"\"}, {\"role\": \"assistant\", \"content\": \"\"}]}\n","```"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699944492338,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"T4WZ9kWPvWvT"},"outputs":[],"source":["import json\n","file_raw_path = '/content/drive/MyDrive/openai/data/raw/training_data.txt'\n","file_processed_path = '/content/drive/MyDrive/openai/data/processed/chat_data.jsonl'\n","# 打开收集的数据文件\n","with open(file_raw_path, 'r', encoding='utf-8') as file:\n","    content = file.read()\n","\n","# 以三个连续的换行符分割成段落\n","paragraphs_level1 = content.split('\\n\\n\\n')\n","\n","# 构建消息列表\n","messages = []\n","\n","for i, paragraph_level1 in enumerate(paragraphs_level1, start=1):\n","    # 在每个段落内再以两个连续的换行符分割内容\n","    paragraphs_level2 = paragraph_level1.split('\\n\\n')\n","\n","    # 初始化消息对象\n","    message = {\"messages\": []}\n","\n","    # 添加系统消息\n","    message[\"messages\"].append({\"role\": \"system\", \"content\": \"你是一名翻译\"})\n","\n","    # 添加第二级段落内容到不同角色的消息\n","    for j, paragraph_level2 in enumerate(paragraphs_level2, start=1):\n","        role = \"user\" if j % 2 == 1 else \"assistant\"\n","        message[\"messages\"].append({\"role\": role, \"content\": paragraph_level2})\n","\n","    # 将消息对象添加到消息列表\n","    messages.append(message)\n","\n","# 将消息列表写入到 chat_data.jsonl 文件\n","with open(file_processed_path, 'w', encoding='utf-8') as jsonl_file:\n","    for message in messages:\n","        jsonl_file.write(json.dumps(message, ensure_ascii=False) + '\\n')\n"]},{"cell_type":"markdown","metadata":{"id":"b1n-zQ5Lv59O"},"source":["## **4.上传数据**\n","将上一步处理完成的JSON-L格式数据，通过files接口上传到OpenAI服务器，获取文件id"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1654,"status":"ok","timestamp":1699944498234,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"ntaUzoOhqDu5","outputId":"29b98bf9-8cb7-4153-b87f-adcf6bc767d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["processed\n"]}],"source":["from openai import OpenAI\n","client = OpenAI()\n","train_file_info = client.files.create(\n","    file=open(file_processed_path, \"rb\"),\n","    purpose='fine-tune'\n",")\n","print(train_file_info.status)"]},{"cell_type":"markdown","metadata":{"id":"mikUtQOgqDu6"},"source":["## **5.创建fine-tuning任务**\n","通过fine_tuning/jobs接口，将上一步上传的数据文件id传入，创建fine-tuning任务，并获取任务id"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1626,"status":"ok","timestamp":1699944523360,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"itw_-upIqDu6","outputId":"e86983ac-fe75-4271-f62b-353ce88bc257"},"outputs":[{"output_type":"stream","name":"stdout","text":["validating_files\n"]}],"source":["file_tuning_job = client.fine_tuning.jobs.create(\n","    training_file=train_file_info.id,\n","    model=\"gpt-3.5-turbo\"\n",")\n","print(file_tuning_job.status)"]},{"cell_type":"markdown","metadata":{"id":"zm9SXorlqDu6"},"source":["## **6.查看微调进度**\n","通过fine_tuning/jobs接口，传入上一步获取的微调任务id，获得进行中的微调任务状态。\n","如果status的值时running，说明该模型还在训练中，此时fine_tuned_model里面没有值，需要继续等待。\n","\n","如果status是succeeded，说明已经训练完成，此时通过fine_tuned_model的值，可以得到微调成功的模型id\n","\n","如果训练成功，开发者账号对应的邮箱，也会收到一封电子邮件，里面会包含模型id。"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":568,"status":"ok","timestamp":1699944579863,"user":{"displayName":"田雪","userId":"12940516194408436158"},"user_tz":-480},"id":"x-o3ulotqDu6","outputId":"4661f562-effe-41f6-e864-eae01e8738c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["running\n"]}],"source":["file_info = client.fine_tuning.jobs.retrieve(file_tuning_job.id)\n","print(file_info.status)"]},{"cell_type":"markdown","metadata":{"id":"hZ29g1Ib0sUW"},"source":["## **7.测试模型**\n","通过Completion API，对微调成功的模型进行效果测试。\n","我们可以按正常GPT模型，例如GPT-3.5-turbo的调用方式，来调用微调好的模型，访问参数完全相同。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oj8rwOhWqDu6"},"outputs":[],"source":["completion = client.chat.completions.create(\n","    model=file_info.fine_tuned_model,\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"你是一名翻译 \"},\n","        {\"role\": \"user\", \"content\": \"全球最大的中文搜索引擎、致力于让网民更便捷地获取信息,找到所求。百度超过千亿的中文网页数据库,可以瞬间找到相关的搜索结果\"}\n","    ],\n","    temperature=0\n",")\n","print(completion.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{"id":"gXjGmL_Qjs9r"},"source":["## 总结\n","至此，一个免安装的微调流程就完成了。需要注意的是，其中用到的数据样本较少，仅用于演示微调的技术实现过程。当然，即使很少的数据也能完成微调，这是GPT-3.5-turbo的优势，但从工作的角度来看，我们仍有必要认真的准备和标记数据。"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}